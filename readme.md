# Prompt Engineering with Llama3

This project demonstrates prompt engineering techniques using the Llama3 model. It includes functions to interact with the Llama3 API and handle various tasks.

## Project Structure

```
.
├── code
│   ├── utils.py
│   ├── L3_getting_started.ipynb
│   └── .env
└── data

README.md


```

## Files

- **utils.py**: Contains utility functions to interact with the Llama2 API.
- **L2_getting_started.ipynb**: Jupyter Notebook demonstrating how to use the functions in `utils.py`.
- **.env**: Environment variables file containing API keys and paths.

## Functions

### `llama`

```python
def llama():
```

This function sends a prompt to the Llama2 API and returns the generated response. It includes parameters for customizing the model, temperature, and other settings.

## Usage

1. Set up your environment variables in the `.env` file.
2. Use the `llama` function in your scripts or Jupyter Notebooks to generate responses from the Llama2 model.

## ☕ Support Me

If you like my work, consider supporting my studies!

Your contributions will help cover fees and materials for my **Computer Science and Engineering studies at UoPeople** starting in September 2025.

Every little bit helps—you can donate from as little as $1.

<a href="https://ko-fi.com/miqueasmd"><img src="https://ko-fi.com/img/githubbutton_sm.svg" /></a>

## Acknowledgements

This project is inspired by the DeepLearning.AI courses. Please visit [DeepLearning.AI](https://www.deeplearning.ai/) for more information and resources.
