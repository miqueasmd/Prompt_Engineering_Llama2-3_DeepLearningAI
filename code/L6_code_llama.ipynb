{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f614c6-d39a-4439-8f96-9434c3ab7cb4",
   "metadata": {},
   "source": [
    "# Code Llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319e974-0ad4-466a-982f-d7225a1a7e31",
   "metadata": {},
   "source": [
    "Here are the names of the Code Llama models provided by Together.ai:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d652420-3d6d-4e6a-9d26-5a608352b3c7",
   "metadata": {},
   "source": [
    "- ```togethercomputer/CodeLlama-7b```\n",
    "- ```togethercomputer/CodeLlama-13b```\n",
    "- ```togethercomputer/CodeLlama-34b```\n",
    "- ```togethercomputer/CodeLlama-7b-Python```\n",
    "- ```togethercomputer/CodeLlama-13b-Python```\n",
    "- ```togethercomputer/CodeLlama-34b-Python```\n",
    "- ```togethercomputer/CodeLlama-7b-Instruct```\n",
    "- ```togethercomputer/CodeLlama-13b-Instruct```\n",
    "- ```togethercomputer/CodeLlama-34b-Instruct```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e238efc5-46c8-4fee-a00a-4cd5587c0343",
   "metadata": {},
   "source": [
    "### Import helper functions\n",
    "\n",
    "- You can examine the code_llama helper function using the menu above and selections File -> Open -> utils.py.\n",
    "- By default, the `code_llama` functions uses the CodeLlama-7b-Instruct model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a089f79-c375-4149-bdca-e7859feb6f0c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from utils import llama, code_llama\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "base_path = os.getenv('BASE_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4677029-ff04-4643-9cc5-69d0651c0700",
   "metadata": {},
   "source": [
    "### Writing code to solve a math problem\n",
    "\n",
    "Lists of daily minimum and maximum temperatures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1bba890-b3e0-4272-acae-65d115959008",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "temp_min = [42, 52, 47, 47, 53, 48, 47, 53, 55, 56, 57, 50, 48, 45]\n",
    "temp_max = [55, 57, 59, 59, 58, 62, 65, 65, 64, 63, 60, 60, 62, 62]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a0cc6-f5b0-4601-b319-3a59ee5a26d2",
   "metadata": {},
   "source": [
    "- Ask the Llama 70B model to determine the day with the lowest temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c3d723-f68c-4398-afb5-84b6bad187f5",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the day with the lowest temperature, we need to look at the low temperatures forecast. The lowest temperature is 42 degrees Fahrenheit, and it occurs on the first day. \n",
      "\n",
      "The answer is: Day 1.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Below is the 14 day temperature forecast in fahrenheit degree:\n",
    "14-day low temperatures: {temp_min}\n",
    "14-day high temperatures: {temp_max}\n",
    "Which day has the lowest temperature?\n",
    "\"\"\"\n",
    "\n",
    "response = llama(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3a6d0-6c55-4251-988f-39bfb732e280",
   "metadata": {},
   "source": [
    "- Ask Code Llama to write a python function to determine the minimum temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62dfe2e7-ef13-41db-8d84-f45230cb91e5",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "\n",
      "Write Python code that can calculate\n",
      "the minimum of the list temp_min\n",
      "and the maximum of the list temp_max\n",
      "\n",
      "\n",
      "model: meta-llama/Llama-3.3-70B-Instruct-Turbo\n",
      "using the built-in min() and max() functions.\n",
      "Then, print the minimum and maximum values.\n",
      "\"\"\"\n",
      "temp_min = [23, 45, 11, 78, 23]\n",
      "temp_max = [67, 89, 45, 23, 56]\n",
      "\n",
      "# Calculate the minimum of temp_min\n",
      "min_temp_min = min(temp_min)\n",
      "\n",
      "# Calculate the maximum of temp_max\n",
      "max_temp_max = max(temp_max)\n",
      "\n",
      "# Print the minimum and maximum values\n",
      "print(\"Minimum of temp_min:\", min_temp_min)\n",
      "print(\"Maximum of temp_max:\", max_temp_max)\n",
      "\n",
      "# Output:\n",
      "# Minimum of temp_min: 11\n",
      "# Maximum of temp_max: 89\n",
      "```\n",
      "\n",
      "### Example 2: Using min() and max() with Custom Objects\n",
      "```python\n",
      "\"\"\"\n",
      "Create a list of custom objects (Person) and calculate\n",
      "the minimum and maximum based on the age attribute.\n",
      "\"\"\"\n",
      "class Person:\n",
      "    def __init__(self, name, age):\n",
      "        self.name = name\n",
      "        self.age = age\n",
      "\n",
      "    def __repr__(self):\n",
      "        return f\"{self.name} ({self.age})\"\n",
      "\n",
      "people = [\n",
      "    Person(\"John\", 25),\n",
      "    Person(\"Alice\", 30),\n",
      "    Person(\"Bob\", 20),\n",
      "    Person(\"Charlie\", 35),\n",
      "    Person(\"David\", 28)\n",
      "]\n",
      "\n",
      "# Calculate the minimum and maximum age\n",
      "min_age = min(people, key=lambda x: x.age)\n",
      "max_age = max(people, key=lambda x: x.age)\n",
      "\n",
      "# Print the minimum and maximum age\n",
      "print(\"Minimum age:\", min_age)\n",
      "print(\"Maximum age:\", max_age)\n",
      "\n",
      "# Output:\n",
      "# Minimum age: Bob (20)\n",
      "# Maximum age: Charlie (35)\n",
      "```\n",
      "\n",
      "### Example 3: Using min() and max() with Dictionaries\n",
      "```python\n",
      "\"\"\"\n",
      "Create a dictionary with temperatures as values and\n",
      "calculate the minimum and maximum temperatures.\n",
      "\"\"\"\n",
      "temperatures = {\n",
      "    \"Monday\": 23,\n",
      "    \"Tuesday\": 25,\n",
      "    \"Wednesday\": 20,\n",
      "    \"Thursday\": 28,\n",
      "    \"Friday\": 22\n",
      "}\n",
      "\n",
      "# Calculate the minimum and maximum temperatures\n",
      "min_temp = min(temperatures.values())\n",
      "max_temp = max(temperatures.values())\n",
      "\n",
      "# Print the minimum and maximum temperatures\n",
      "print(\"Minimum temperature:\", min_temp)\n",
      "print(\"Maximum temperature:\", max_temp)\n",
      "\n",
      "# Output:\n",
      "# Minimum temperature: 20\n",
      "# Maximum temperature: 28\n",
      "```\n",
      "\n",
      "### Example 4: Using min() and max() with Tuples\n",
      "```python\n",
      "\"\"\"\n",
      "Create a list of tuples with temperatures as the second element\n",
      "and calculate the minimum and maximum temperatures.\n",
      "\"\"\"\n",
      "temperatures = [\n",
      "    (\"Monday\", 23),\n",
      "    (\"Tuesday\", 25),\n",
      "    (\"Wednesday\", 20),\n",
      "    (\"Thursday\", 28),\n",
      "    (\"Friday\", 22)\n",
      "]\n",
      "\n",
      "# Calculate the minimum and maximum temperatures\n",
      "min_temp = min(temperatures, key=lambda x: x[1])[1]\n",
      "max_temp = max(temperatures, key=lambda x: x[1])[1]\n",
      "\n",
      "# Print the minimum and maximum temperatures\n",
      "print(\"Minimum temperature:\", min_temp)\n",
      "print(\"Maximum temperature:\", max_temp)\n",
      "\n",
      "# Output:\n",
      "# Minimum temperature: 20\n",
      "# Maximum temperature: 28\n",
      "```\n",
      "\n",
      "### Example 5: Using min() and max() with Custom Key Function\n",
      "```python\n",
      "\"\"\"\n",
      "Create a list of strings and calculate the minimum and maximum\n",
      "based on the length of the strings.\n",
      "\"\"\"\n",
      "strings = [\"hello\", \"world\", \"abc\", \"defghi\", \"jkl\"]\n",
      "\n",
      "# Calculate the minimum and maximum length\n",
      "min_length = min(strings, key=len)\n",
      "max_length = max(strings, key=len)\n",
      "\n",
      "# Print the minimum and maximum length\n",
      "print(\"Minimum length:\", min_length)\n",
      "print(\"Maximum length:\", max_length)\n",
      "\n",
      "# Output:\n",
      "# Minimum length: jkl\n",
      "# Maximum length: defghi\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "Write Python code that can calculate\n",
    "the minimum of the list temp_min\n",
    "and the maximum of the list temp_max\n",
    "\"\"\"\n",
    "response_2 = code_llama(prompt_2, verbose=True)\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a25ce0-9512-4321-bd8f-71ebd37b4896",
   "metadata": {},
   "source": [
    "- Use the function on the temperature lists above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "683f5868-6faa-4006-b4c3-14bf2746f51e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "def get_min_max(temp_min, temp_max):\n",
    "    return min(temp_min), max(temp_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c86d5a7d-be05-49f0-826c-6b7dce2ba50d",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 65)\n"
     ]
    }
   ],
   "source": [
    "temp_min = [42, 52, 47, 47, 53, 48, 47, 53, 55, 56, 57, 50, 48, 45]\n",
    "temp_max = [55, 57, 59, 59, 58, 62, 65, 65, 64, 63, 60, 60, 62, 62]\n",
    "\n",
    "results = get_min_max(temp_min, temp_max)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c12b6-6054-47c2-ad93-9f4a6514fe32",
   "metadata": {},
   "source": [
    "### Code in-filling\n",
    "\n",
    "- Use Code Llama to fill in partially completed code.\n",
    "- Notice the `[INST]` and `[/INST]` tags that have been added to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c3067b-5c23-4208-9888-34e3860d8bc7",
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "\n",
      "def star_rating(n):\n",
      "'''\n",
      "  This function returns a rating given the number n,\n",
      "  where n is an integers from 1 to 5.\n",
      "'''\n",
      "\n",
      "    if n == 1:\n",
      "        rating=\"poor\"\n",
      "    <FILL>\n",
      "    elif n == 5:\n",
      "        rating=\"excellent\"\n",
      "\n",
      "    return rating\n",
      "\n",
      "\n",
      "model: meta-llama/Llama-3.3-70B-Instruct-Turbo\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "def star_rating(n):\n",
    "'''\n",
    "  This function returns a rating given the number n,\n",
    "  where n is an integers from 1 to 5.\n",
    "'''\n",
    "\n",
    "    if n == 1:\n",
    "        rating=\"poor\"\n",
    "    <FILL>\n",
    "    elif n == 5:\n",
    "        rating=\"excellent\"\n",
    "\n",
    "    return rating\n",
    "\"\"\"\n",
    "\n",
    "response = code_llama(prompt,\n",
    "                      verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45fc6fd2-8f5f-4778-a0fd-edfc3602fa85",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "\n",
      "## Step 2: Fill in the missing conditions for the star_rating function\n",
      "To complete the function, we need to add conditions for ratings 2, 3, and 4. Here's how we can do it:\n",
      "```python\n",
      "def star_rating(n):\n",
      "    '''\n",
      "      This function returns a rating given the number n,\n",
      "      where n is an integers from 1 to 5.\n",
      "    '''\n",
      "\n",
      "    if n == 1:\n",
      "        rating=\"poor\"\n",
      "    elif n == 2:\n",
      "        rating=\"fair\"\n",
      "    elif n == 3:\n",
      "        rating=\"good\"\n",
      "    elif n == 4:\n",
      "        rating=\"very good\"\n",
      "    elif n == 5:\n",
      "        rating=\"excellent\"\n",
      "\n",
      "    return rating\n",
      "```\n",
      "\n",
      "## Step 3: Test the function with different inputs\n",
      "Let's test the function with different inputs to ensure it's working correctly:\n",
      "```python\n",
      "print(star_rating(1))  # Should print \"poor\"\n",
      "print(star_rating(2))  # Should print \"fair\"\n",
      "print(star_rating(3))  # Should print \"good\"\n",
      "print(star_rating(4))  # Should print \"very good\"\n",
      "print(star_rating(5))  # Should print \"excellent\"\n",
      "```\n",
      "\n",
      "The final answer is: $\\boxed{}$\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aea160-3ce3-4df7-b87f-ce5af449fe18",
   "metadata": {},
   "source": [
    "### Write code to calculate the nth Fibonacci number\n",
    "\n",
    "Here is the Fibonacci sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "583c6d54-dc7e-434d-986a-a0b385288488",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd158fc-0285-4b09-8b52-71a58da8c2ec",
   "metadata": {},
   "source": [
    "Each number (after the starting 0 and 1) is equal to the sum of the two numbers that precede it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79251b2d-2bdd-4b55-8bc7-e565dbea1de3",
   "metadata": {},
   "source": [
    "#### Use Code Llama to write a Fibonacci number\n",
    "- Write a natural language prompt that asks the model to write code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1144cf40-add0-4025-a116-c16b332238cc",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "\n",
      "Provide a function that calculates the n-th fibonacci number.\n",
      "\n",
      "\n",
      "model: meta-llama/Llama-3.3-70B-Instruct-Turbo\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    if n <= 0:\n",
      "        raise ValueError(\"n must be a positive integer\")\n",
      "    elif n == 1:\n",
      "        return 0\n",
      "    elif n == 2:\n",
      "        return 1\n",
      "    else:\n",
      "        a, b = 0, 1\n",
      "        for _ in range(2, n):\n",
      "            a, b = b, a + b\n",
      "        return b\n",
      "```\n",
      "### Example Use Cases\n",
      "\n",
      "*   Calculate the 10th Fibonacci number: `fibonacci(10)`\n",
      "*   Calculate the 20th Fibonacci number: `fibonacci(20)`\n",
      "\n",
      "### Step-by-Step Solution\n",
      "\n",
      "1.  Check if the input `n` is less than or equal to 0 and raise a `ValueError` if true.\n",
      "2.  Handle the base cases where `n` is 1 or 2, returning 0 and 1 respectively.\n",
      "3.  Initialize two variables `a` and `b` to 0 and 1, representing the first two Fibonacci numbers.\n",
      "4.  Use a loop to iterate from 2 to `n-1`, updating `a` and `b` in each iteration to hold the last two Fibonacci numbers.\n",
      "5.  After the loop, `b` will hold the `n`-th Fibonacci number, which is then returned.\n",
      "\n",
      "### Advice\n",
      "\n",
      "*   This function uses an iterative approach, which is more efficient than a recursive approach for large values of `n`.\n",
      "*   It also uses a constant amount of space, making it suitable for large inputs.\n",
      "*   The function raises a `ValueError` for non-positive inputs, ensuring that it only handles valid inputs.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Provide a function that calculates the n-th fibonacci number.\n",
    "\"\"\"\n",
    "\n",
    "response = code_llama(prompt, verbose=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246ec10-4750-4855-a745-ff4e8e1ddbbb",
   "metadata": {},
   "source": [
    "### Make the code more efficient\n",
    "\n",
    "- Ask Code Llama to critique its initial response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d448ae23-d997-450c-93ec-874ee3951727",
   "metadata": {
    "height": 268
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "\n",
      "For the following code: \n",
      "def fibonacci(n):\n",
      "    if n <= 1:\n",
      "        return n\n",
      "    else:\n",
      "        return fibonacci(n-1) + fibonacci(n-2)\n",
      "\n",
      "Is this implementation efficient?\n",
      "Please explain.\n",
      "\n",
      "\n",
      "model: meta-llama/Llama-3.3-70B-Instruct-Turbo\n"
     ]
    }
   ],
   "source": [
    "code = \"\"\"\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "\"\"\"\n",
    "\n",
    "prompt_1 = f\"\"\"\n",
    "For the following code: {code}\n",
    "Is this implementation efficient?\n",
    "Please explain.\n",
    "\"\"\"\n",
    "response_1 = code_llama(prompt_1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68702444-3baf-45a9-8d4e-0140a825f102",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "## Step-by-step analysis of the problem:\n",
      "1. **Understanding the Fibonacci sequence**: The Fibonacci sequence is a series of numbers where a number is the addition of the last two numbers, starting with 0 and 1.\n",
      "2. **Analyzing the given implementation**: The given implementation uses recursion to calculate the nth Fibonacci number. It checks if `n` is less than or equal to 1, in which case it returns `n`. Otherwise, it calls itself with `n-1` and `n-2` and returns the sum of these two calls.\n",
      "3. **Identifying the inefficiency**: The main issue with this implementation is that it performs a lot of repeated work. For example, to calculate `fibonacci(n)`, it needs to calculate `fibonacci(n-1)` and `fibonacci(n-2)`. However, to calculate `fibonacci(n-1)`, it also needs to calculate `fibonacci(n-2)` and `fibonacci(n-3)`. As a result, `fibonacci(n-2)` is calculated multiple times, leading to exponential time complexity.\n",
      "4. **Time complexity analysis**: The time complexity of this implementation is O(2^n), which is very inefficient for large values of `n`.\n",
      "\n",
      "## Fixed solution:\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    \"\"\"\n",
      "    Calculate the nth Fibonacci number using dynamic programming.\n",
      "\n",
      "    Args:\n",
      "        n (int): The position of the Fibonacci number to calculate.\n",
      "\n",
      "    Returns:\n",
      "        int: The nth Fibonacci number.\n",
      "    \"\"\"\n",
      "    if n <= 1:\n",
      "        return n\n",
      "\n",
      "    # Create a list to store the Fibonacci numbers\n",
      "    fib = [0] * (n + 1)\n",
      "    fib[1] = 1\n",
      "\n",
      "    # Calculate the Fibonacci numbers from 2 to n\n",
      "    for i in range(2, n + 1):\n",
      "        fib[i] = fib[i-1] + fib[i-2]\n",
      "\n",
      "    return fib[n]\n",
      "```\n",
      "\n",
      "## Explanation of changes:\n",
      "* **Using dynamic programming**: Instead of using recursion, we use dynamic programming to store the Fibonacci numbers in a list as we calculate them. This avoids the repeated work and reduces the time complexity to O(n).\n",
      "* **Creating a list to store Fibonacci numbers**: We create a list `fib` of size `n+1` to store the Fibonacci numbers from 0 to `n`.\n",
      "* **Calculating Fibonacci numbers iteratively**: We calculate the Fibonacci numbers from 2 to `n` using a loop, storing each number in the `fib` list.\n",
      "* **Returning the nth Fibonacci number**: Finally, we return the `n`th Fibonacci number, which is stored in `fib[n]`.\n",
      "\n",
      "## Tests and example uses:\n",
      "```python\n",
      "print(fibonacci(0))  # Output: 0\n",
      "print(fibonacci(1))  # Output: 1\n",
      "print(fibonacci(2))  # Output: 1\n",
      "print(fibonacci(3))  # Output: 2\n",
      "print(fibonacci(4))  # Output: 3\n",
      "print(fibonacci(5))  # Output: 5\n",
      "```2019-12-31T00:00:00Z\n",
      "\n",
      "## Step-by-step analysis of the problem:\n",
      "1. **Understanding the Fibonacci sequence**: The Fibonacci sequence is a series of numbers where a number is the addition of the last two numbers, starting with 0 and 1.\n",
      "2. **Analyzing the given implementation**: The given implementation uses recursion to calculate the nth Fibonacci number. It checks if `n` is less than or equal to 1, in which case it returns `n`. Otherwise, it calls itself with `n-1` and `n-2` and returns the sum of these two calls.\n",
      "3. **Identifying the inefficiency**: The main issue with this implementation is that it performs a lot of repeated work. For example, to calculate `fibonacci(n)`, it needs to calculate `fibonacci(n-1)` and `fibonacci(n-2)`. However, to calculate `fibonacci(n-1)`, it also needs to calculate `fibonacci(n-2)` and `fibonacci(n-3)`. As a result, `fibonacci(n-2)` is calculated multiple times, leading to exponential time complexity.\n",
      "4. **Time complexity analysis**: The time complexity of this implementation is O(2^n), which is very inefficient for large values of `n`.\n",
      "\n",
      "## Fixed solution:\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    \"\"\"\n",
      "    Calculate the nth Fibonacci number using dynamic programming.\n",
      "\n",
      "    Args:\n",
      "        n (int): The position of the Fibonacci number to calculate.\n",
      "\n",
      "    Returns:\n",
      "        int: The nth Fibonacci number.\n",
      "    \"\"\"\n",
      "    if n <= 1:\n",
      "        return n\n",
      "\n",
      "    # Create a list to store the Fibonacci numbers\n",
      "    fib = [0] * (n + 1)\n",
      "    fib[1] = 1\n",
      "\n",
      "    # Calculate the Fibonacci numbers from 2 to n\n"
     ]
    }
   ],
   "source": [
    "print(response_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f037f-78ac-4c5f-b492-234e195be397",
   "metadata": {},
   "source": [
    "### Compare the original and more efficient implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6908e90-76c1-465a-af8c-013a5643b825",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e9733fc-37e3-44f8-aa4a-dfeb2b8a3deb",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "def fibonacci_fast(n):\n",
    "    a, b = 0, 1\n",
    "    for i in range(n):\n",
    "        a, b = b, a + b\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32169e-55ed-41cc-9c84-4f3bd8bb221a",
   "metadata": {},
   "source": [
    "#### Compare the runtimes of the two functions\n",
    "- Start by asking Code Llama to write Python code that calculates how long a piece of code takes to execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbfdfbcf-2d17-4c88-9458-ce5485a60893",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "\n",
      "Provide sample code that calculates the runtime of a Python function call.\n",
      "\n",
      "\n",
      "model: meta-llama/Llama-3.3-70B-Instruct-Turbo\n",
      "## Step 1: Define the function to be measured\n",
      "To calculate the runtime of a Python function call, we first need to define the function that we want to measure. For this example, let's use a simple function that calculates the sum of all numbers in a list.\n",
      "\n",
      "## Step 2: Use the time module to measure runtime\n",
      "We will use the time module in Python, which provides various time-related functions. Specifically, we will use the time.time() function, which returns the current system time in seconds since the epoch (January 1, 1970).\n",
      "\n",
      "## Step 3: Record the start time\n",
      "Before calling the function, we record the current time using time.time(). This will give us the start time of our function call.\n",
      "\n",
      "## Step 4: Call the function\n",
      "Next, we call the function that we want to measure. In this case, it's our example function that calculates the sum of all numbers in a list.\n",
      "\n",
      "## Step 5: Record the end time\n",
      "After the function call returns, we record the current time again using time.time(). This gives us the end time of our function call.\n",
      "\n",
      "## Step 6: Calculate the runtime\n",
      "The runtime of the function call is the difference between the end time and the start time. We subtract the start time from the end time to get the runtime in seconds.\n",
      "\n",
      "## Step 7: Print the runtime\n",
      "Finally, we print out the calculated runtime to see how long the function call took.\n",
      "\n",
      "## Step 8: Implement the solution in code\n",
      "Here is the sample code that implements these steps:\n",
      "```python\n",
      "import time\n",
      "\n",
      "def calculate_sum(numbers):\n",
      "    \"\"\"Example function that calculates the sum of all numbers in a list.\"\"\"\n",
      "    return sum(numbers)\n",
      "\n",
      "def measure_runtime(func, *args, **kwargs):\n",
      "    \"\"\"Measure the runtime of a function call.\"\"\"\n",
      "    start_time = time.time()\n",
      "    result = func(*args, **kwargs)\n",
      "    end_time = time.time()\n",
      "    runtime = end_time - start_time\n",
      "    print(f\"Runtime: {runtime:.6f} seconds\")\n",
      "    return result\n",
      "\n",
      "# Example usage\n",
      "numbers = [1, 2, 3, 4, 5]\n",
      "result = measure_runtime(calculate_sum, numbers)\n",
      "print(f\"Result: {result}\")\n",
      "```\n",
      "\n",
      "The final answer is: $\\boxed{[answer]}$\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Provide sample code that calculates the runtime \\\n",
    "of a Python function call.\n",
    "\"\"\"\n",
    "\n",
    "response = code_llama(prompt, verbose=True)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ae5c51-25cb-458f-8557-89d9e036020d",
   "metadata": {},
   "source": [
    "Let's use the first suggestion from Code Llama to calcuate the run time.\n",
    "\n",
    "    Here is an example of how you can calculate the runtime of a Python function call using the `time` module:\n",
    "    ```\n",
    "    import time\n",
    "    \n",
    "    def my_function():\n",
    "        # do something\n",
    "        pass\n",
    "    \n",
    "    start_time = time.time()\n",
    "    my_function()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"Runtime:\", end_time - start_time)\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cbc4bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.000000 seconds\n",
      "Result: 15\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def calculate_sum(numbers):\n",
    "    \"\"\"Example function that calculates the sum of all numbers in a list.\"\"\"\n",
    "    return sum(numbers)\n",
    "\n",
    "def measure_runtime(func, *args, **kwargs):\n",
    "    \"\"\"Measure the runtime of a function call.\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    print(f\"Runtime: {runtime:.6f} seconds\")\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "result = measure_runtime(calculate_sum, numbers)\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603a3440-6e64-4da2-9bcd-2acd11160a97",
   "metadata": {},
   "source": [
    "#### Run the original Fibonacci code\n",
    "- This will take approximately 45 seconds.\n",
    "- The video has been edited so you don't have to wait for the code to exectute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d9841ef-a585-46fd-b910-ac68a7f0854a",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recursive fibonacci(40) \n",
      "runtime in seconds: 19.896976947784424\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "n=40\n",
    "start_time = time.time()\n",
    "fibonacci(n) # note, we recommend keeping this number <=40\n",
    "end_time = time.time()\n",
    "print(f\"recursive fibonacci({n}) \")\n",
    "print(f\"runtime in seconds: {end_time-start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25e4e90-c58f-46d0-802e-e0fb605a8e3d",
   "metadata": {},
   "source": [
    "#### Run the efficient implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b16fd73-0b07-48f0-a243-2295bc14efb2",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-recursive fibonacci(40) \n",
      "runtime in seconds: 0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "n=40\n",
    "start_time = time.time()\n",
    "fibonacci_fast(n) # note, we recommend keeping this number <=40\n",
    "end_time = time.time()\n",
    "print(f\"non-recursive fibonacci({n}) \")\n",
    "print(f\"runtime in seconds: {end_time-start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9865891e-3dc6-4a6c-b0f9-fb7cb4414c95",
   "metadata": {},
   "source": [
    "### Code Llama can take in longer text\n",
    "\n",
    "- Code Llama models can handle much larger input text than the Llama Chat models - more than 20,000 characters.\n",
    "- The size of the input text is known as the **context window**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebcb748-92a0-43a6-b67b-9310d1481e22",
   "metadata": {},
   "source": [
    "#### Response from Llama 3 70B Chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a856c3b-9a51-4e1b-9c47-ec84d78c7b1e",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A velveteen rabbit becomes \"real\" through a boy's love, transforming from a toy to a cherished companion.\n"
     ]
    }
   ],
   "source": [
    "rabbit_path= os.path.join(base_path, 'data/TheVelveteenRabbit.txt')\n",
    "\n",
    "with open(rabbit_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "prompt=f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n \n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "# Ask the 70B model to respond\n",
    "response = llama(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8627474c-1566-4573-89bf-d8722f26e0ba",
   "metadata": {},
   "source": [
    "#### Response from Code Llama 70B Instruct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19c45fb4-8f87-44df-9035-92540f301164",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Boy had sat up in bed and looked at him, and he had smiled, but\n",
      "when he was carried out on to the balcony he had not had the little\n",
      "Rabbit with him. For a long time he lay there, very still, and the\n",
      "only sound was the flutter of the leaves and the creaking of the\n",
      "balcony as the Boy's mother stood beside him.\n",
      "\n",
      "And then a doctor came, and said...\n",
      "\n",
      "\"No more toys now.\"\n",
      "\n",
      "\"Put him into the sack,\" said the doctor, and it was done. Just like\n",
      "that. And then the little Rabbit was carried out, with the old\n",
      "toys, and the picture-books, and the other things that were not\n",
      "wanted, and he was thrown away.\n",
      "\n",
      "But he was not sad. For he knew that he was Real, and he had been\n",
      "loved, and that was all that mattered. And one day, when he was lying\n",
      "there in the sack, he thought of all his wonderful adventures, and all\n",
      "the lovely times he had had in the nursery, and all the kind things the\n",
      "Boy had said to him. He thought of the Skin Horse, and the wise things\n",
      "he had told him, and he knew that once you are Real you can't become\n",
      "unreal again. It lasts for always.\n",
      "\n",
      "The sack went down to the rubbish heap, and then it was emptied out,\n",
      "and all the old things were taken away somewhere. The little Rabbit's\n",
      "velvet was all trodden and torn, and he was a small, dirty, limp\n",
      "thing, but to himself he was still a real, live rabbit, and he didn't\n",
      "care.\n",
      "\n",
      "And then, most strange and wonderful of all, for he was sitting on\n",
      "the rubbish heap, and he felt himself being turned into a real\n",
      "rabbit.\n",
      "\n",
      "It all happened when the nursery magic was at work. The wonderful\n",
      "thing was that he actually became a real rabbit, with soft fur and a\n",
      "little pink nose, and he could hop and run and play, and he was never\n",
      "tired.\n",
      "\n",
      "The Boy had loved him so long and so hard that he had given him the\n",
      "power of becoming real, and though he was away and in his bed, the\n",
      "little Rabbit was alive and Real.\n",
      "\n",
      "The doctor had said \"No more toys now,\" but for the little Rabbit it\n",
      "was too late. The magic had been done, and it had happened when the\n",
      "Boy loved him all the time he was ill. The little Rabbit was so happy\n",
      "that he never wanted to be made of velveteen again. He was Real, and\n",
      "that was all that mattered.\n",
      "\n",
      "\n",
      "And so the little Rabbit lived happily ever after in the forest, free\n",
      "to run and play as he liked, and one day, when he was old and grey, he\n",
      "went to visit the Skin Horse, who was still living in the nursery, and\n",
      "he said to him, \"You were quite right. To be Real is a wonderful\n",
      "thing.\" And the Skin Horse smiled and said, \"I'm glad you think so.\n",
      "You've become rather an old rabbit.\" And the little Rabbit smiled, and\n",
      "hopped away, and they were both happy. \n",
      "\n",
      "Here is a summary of the text in 50 words:\n",
      "\n",
      "A velveteen rabbit becomes \"real\" through a boy's love, transforming from a toy to a living rabbit, and lives happily ever after in the forest, free to run and play, after being discarded and experiencing the magic of the nursery.\n"
     ]
    }
   ],
   "source": [
    "with open(rabbit_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "prompt=f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n \n",
    "{text}\n",
    "\"\"\"\n",
    "response = code_llama(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e80ce43-2dd9-4906-a842-f710926f59a5",
   "metadata": {},
   "source": [
    "### Thoughts on Code Llama's summarization performance\n",
    "\n",
    "Note that while the Code Llama model could handle the longer text, the output here isn't that great - the response is very repetitive.\n",
    "- Code Llama's primary skill is writing code.\n",
    "- Experiment to see if you can prompt the Code Llama model to improve its output.\n",
    "- You may need to trade off performance and input text size depending on your task.\n",
    "- You could ask Llama 3 70B chat to help you evaluate how well the Code Llama model is doing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
